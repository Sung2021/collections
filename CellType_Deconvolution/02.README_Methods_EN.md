# Deconvolution Methods Overview (English)

## üìå What is Deconvolution?

**Deconvolution** is an analytical method to estimate **cell type proportions** from bulk RNA-seq data.

### Basic Principle

```
Bulk RNA-seq = Œ£ (Cell type proportion √ó Cell type expression profile)
```

Mathematical formula:
```
Y = X √ó Œ≤

Y: Bulk RNA-seq expression (genes √ó samples)
X: Signature matrix (genes √ó cell types)
Œ≤: Cell type proportions (cell types √ó samples) ‚Üê What we want to estimate!
```

### Goal
Estimate **Œ≤ (cell type proportions)** from known X (signature matrix) and Y (bulk data)

---

## üî¨ 4 Deconvolution Methods

### 1. NNLS (Non-Negative Least Squares)

#### Principle
- **Least Squares** with **non-negativity constraint**
- Reflects biological constraint that cell type proportions must be ‚â• 0

#### Formula
```
minimize: ||Y - X√óŒ≤||¬≤
subject to: Œ≤ ‚â• 0
```

#### Advantages
‚úÖ Biologically valid (no negative proportions)  
‚úÖ Stable and fast  
‚úÖ Good performance in most cases  

#### Disadvantages
‚ùå No sum-to-1 constraint (proportions may not sum exactly to 1)  
‚ùå Sensitive to outliers  

#### When to Use?
- **Default choice**: First attempt in most cases
- When data is clean with low noise

#### R Code
```r
library(nnls)

deconvolve_nnls <- function(bulk, signature) {
  fit <- nnls(A = as.matrix(signature), b = bulk)
  prop <- coef(fit)
  prop <- prop / sum(prop)  # Sum-to-1 normalization
  return(prop)
}
```

---

### 2. QP (Quadratic Programming)

#### Principle
- Similar to NNLS but with **sum-to-1 constraint**
- Solves optimization problem rigorously using quadratic programming

#### Formula
```
minimize: ||Y - X√óŒ≤||¬≤
subject to: 
  - Œ≤ ‚â• 0
  - Œ£Œ≤·µ¢ = 1  ‚Üê sum-to-1 constraint
```

#### Advantages
‚úÖ Exact proportions (sum exactly to 1)  
‚úÖ Mathematically rigorous  
‚úÖ Stable with extreme proportions  

#### Disadvantages
‚ùå Slightly slower than NNLS  
‚ùå Sensitive to outliers  

#### When to Use?
- When **exact proportions** are important
- When expecting extreme proportions (e.g., 90%, 5%, 5%)
- When rigorous numbers needed for reporting/publication

#### R Code
```r
library(quadprog)

deconvolve_qp <- function(bulk, signature) {
  n_types <- ncol(signature)
  
  # QP setup
  Dmat <- t(signature) %*% signature
  dvec <- t(signature) %*% bulk
  
  # Constraints: sum(Œ≤) = 1, Œ≤ ‚â• 0
  Amat <- cbind(rep(1, n_types), diag(n_types))
  bvec <- c(1, rep(0, n_types))
  
  result <- solve.QP(Dmat, dvec, Amat, bvec, meq = 1)
  return(result$solution)
}
```

---

### 3. Robust Regression

#### Principle
- Uses **Huber loss**: Loss function less sensitive to outliers
- Reduces influence of extreme values for robust estimation

#### Formula
```
minimize: Œ£ œÅ(Y·µ¢ - X√óŒ≤)

œÅ(r) = { r¬≤/2           if |r| ‚â§ k  (small error)
       { k|r| - k¬≤/2    if |r| > k  (large error - outlier)
```

#### Advantages
‚úÖ **Resistant to outliers** ‚≠ê (biggest advantage)  
‚úÖ Stable with noisy data  
‚úÖ Advantageous with batch effects  

#### Disadvantages
‚ùå Slower than OLS  
‚ùå May produce negative proportions (requires post-processing)  

#### When to Use?
- **Real-world data**: When noise/outliers are abundant
- When batch effects are suspected
- When unsure about data quality

#### R Code
```r
library(MASS)

deconvolve_robust <- function(bulk, signature) {
  fit <- rlm(bulk ~ as.matrix(signature) - 1, maxit = 100)
  
  prop <- coef(fit)
  prop[prop < 0] <- 0  # Remove negatives
  prop <- prop / sum(prop)
  return(prop)
}
```

---

### 4. OLS (Ordinary Least Squares)

#### Principle
- Most basic **linear regression**
- Simply minimizes sum of squared errors without constraints

#### Formula
```
minimize: ||Y - X√óŒ≤||¬≤
(no constraints)
```

#### Advantages
‚úÖ Fastest  
‚úÖ Simple implementation  
‚úÖ Well-established theory  

#### Disadvantages
‚ùå **May produce negative proportions** (biologically inappropriate)  
‚ùå Very sensitive to outliers  
‚ùå Heavily influenced by extreme values  

#### When to Use?
- **Baseline comparison**: When comparing performance with other methods
- Ideal conditions (clean data, low noise)
- Educational/research purposes

#### R Code
```r
deconvolve_ols <- function(bulk, signature) {
  fit <- lm(bulk ~ as.matrix(signature) - 1)
  
  prop <- coef(fit)
  prop[prop < 0] <- 0  # Remove negatives
  prop <- prop / sum(prop)
  return(prop)
}
```

---

## üìä Method Comparison Summary

| Method | Speed | Outlier Resistance | Sum-to-1 | Non-negative | Recommended Use |
|--------|-------|-------------------|----------|--------------|-----------------|
| **NNLS** | Fast | Moderate | ‚ùå (post-proc) | ‚úÖ | Default choice |
| **QP** | Moderate | Moderate | ‚úÖ | ‚úÖ | Exact proportions |
| **Robust** | Slow | ‚úÖ Strong | ‚ùå (post-proc) | ‚ùå (post-proc) | Real-world data |
| **OLS** | Very fast | ‚ùå Weak | ‚ùå | ‚ùå | Baseline comparison |

---

## üéØ Practical Usage Guide

### Recommendations by Scenario

#### 1Ô∏è‚É£ Clean Data (Ideal Conditions)
‚Üí **NNLS** or **QP**

#### 2Ô∏è‚É£ Noisy Real-World Data
‚Üí **Robust Regression** ‚≠ê

#### 3Ô∏è‚É£ Suspected Batch Effects
‚Üí **Robust Regression**

#### 4Ô∏è‚É£ Expected Extreme Proportions (e.g., 90/5/5)
‚Üí **QP**

#### 5Ô∏è‚É£ Need Quick Exploration
‚Üí **NNLS**

#### 6Ô∏è‚É£ Want to Compare Multiple Methods
‚Üí **Run all methods** and check agreement

---

## üí° Practical Tips

### 1. Run Multiple Methods Simultaneously
```r
compare_methods <- function(bulk, signature, true_prop) {
  results <- data.frame(
    NNLS = deconvolve_nnls(bulk, signature),
    QP = deconvolve_qp(bulk, signature),
    Robust = deconvolve_robust(bulk, signature),
    OLS = deconvolve_ols(bulk, signature)
  )
  return(results)
}
```

### 2. Check Result Consistency
- If all 4 methods **agree** ‚Üí Good data quality, results are reliable
- If all 4 methods **disagree** ‚Üí Suspect data issues, prioritize Robust results

### 3. Validation Strategy
- With ground truth: Compare with actual proportions
- Without ground truth:
  - Check agreement across methods
  - Test with simulations
  - Use biological prior knowledge

---

## üìö References

1. **NNLS**: Lawson & Hanson (1974) "Solving Least Squares Problems"
2. **Quadratic Programming**: Goldfarb & Idnani (1983)
3. **Robust Regression**: Huber (1981) "Robust Statistics"
4. **Deconvolution Review**: Newman et al. (2019) Nature Methods

---

## üîó Related Files

- `02.Deconvolution.Rmd`: Basic comparative analysis
- `02.Deconvolution_v2.Rmd`: Robustness tests (noise, outliers, etc.)
- `01.read_h5ad_in_R.Rmd`: Signature matrix generation

---

**Date**: December 29, 2025  
**Author**: Sungryeol Park
